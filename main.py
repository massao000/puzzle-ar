import streamlit as st
from streamlit_webrtc import webrtc_streamer
import threading

import cv2
# import cv2.aruco as aruco
import numpy as np
import os
import av
import random
from PIL import Image
import glob

from package import *

st.set_page_config(
    page_title="AR puzzle",
    page_icon="ğŸ§Š",
    layout="wide"
)

video = VideoProcessor()

# ARãƒãƒ¼ã‚«ãƒ¼ã®ãƒ©ãƒ³ãƒ€ãƒ ãŒã§ãã‚‹ã‹
is_random_img = False

option = st.sidebar.selectbox(
    label = "ãƒ‘ã‚ºãƒ«ã‚µã‚¤ã‚º",
    options = ["2x2", "3x3", "4x4", "5x5", "3x2"]
)

if option == "2x2":
    video.rows, video.cols = 2, 2
    dsize=(500, 500)
elif option == "3x3":
    video.rows, video.cols = 3, 3
    dsize=(500, 500)
elif option == "4x4":
    video.rows, video.cols = 4, 4
    dsize=(500, 500)
elif option == "5x5":
    video.rows, video.cols = 5, 5
    dsize=(500, 500)
elif option == "3x2":
    video.rows, video.cols = 2, 3
    video.imgs = glob.glob(f'imgs/2-1/*')
    dsize=(750, 500)

# æœªå®Ÿè£…
st.sidebar.radio(
    label = "ã‚€ãšã‹ã—ã•",
    options = ["ã‹ã‚“ãŸã‚“", "ãµã¤ã†", "ã‚€ãšã‹ã—ã„"]
)

with open("ãƒãƒ¼ã‚«big.pdf", "rb") as pdf_file:
    PDFbyte = pdf_file.read()

st.sidebar.download_button(
    label="ARãƒãƒ¼ã‚«ãƒ¼",
    data=PDFbyte,
    file_name="ARmarker.pdf",
    mime='application/octet-stream')


placeholder_che = st.empty()
# 
agree = st.sidebar.button('ARãƒãƒ¼ã‚«ãƒ¼ã§ç”»åƒã®ãƒ©ãƒ³ãƒ€ãƒ æŠ½é¸', key='q')

if not agree:
    randm_img = st.sidebar.button('å˜ç™ºãƒ©ãƒ³ãƒ€ãƒ æŠ½é¸')
    if randm_img:
        try:
            video.original_img = cv2.imread(random.choice(video.imgs))
            video.original_img = cv2.resize(video.original_img, dsize=dsize)
            # print(video.original_img)
            # å…ƒç”»åƒ, æ¯”è¼ƒç”»åƒ
            video.img, video.comparison_img = video.imgCut(video.original_img, video.rows, video.cols)
            # print(video.img)
        except:
            pass
    else:
        try:
            video.original_img = cv2.imread(random.choice(video.imgs))
            video.original_img = cv2.resize(video.original_img, dsize=dsize)
            # å…ƒç”»åƒ, æ¯”è¼ƒç”»åƒ
            video.img, video.comparison_img = video.imgCut(video.original_img, video.rows, video.cols)
        except:
            pass
else:
    st.sidebar.button('OFF')
    st.sidebar.info('ãƒãƒ¼ã‚«ãƒ¼50ç•ªã§ã®ãƒ©ãƒ³ãƒ€ãƒ æŠ½é¸ã§ã™')

# ã‚«ãƒ¡ãƒ©ãƒ¡ã‚¤ãƒ³å‡¦ç†
def video_frame_callback(frame):
    global is_random_img
    global agree
    
    frame = frame.to_ndarray(format = 'bgr24')
    
    # é»’è‰²ã®èƒŒæ™¯ã®ç”Ÿæˆ
    frame2 = np.zeros(frame.copy().shape, dtype=np.uint8)
    frame2.fill(0)
    
    # h, w = self.original_img.shape[:2]
    # frame[0:h, 0:w] = self.original_img
    
    #ã€€ãƒãƒ¼ã‚«ã®æ¤œå‡º
    dictionary = video.aruco.Dictionary_get(video.aruco.DICT_5X5_50)
    # dictionary = video.aruco.getPredefinedDictionary(video.aruco.DICT_5X5_50)
    
    # corners:ãƒãƒ¼ã‚«ã®è§’ ids:ãƒãƒ¼ã‚«ID
    corners, ids, rejectedImgPoints = video.aruco.detectMarkers(frame, dictionary)
    # print(corners * 2)
    # æ¤œå‡ºã—ãŸãƒãƒ¼ã‚«ãƒ¼ã®æ¤œå‡º å›²ã¿IDè¡¨ç¤º
    frame = video.aruco.drawDetectedMarkers(frame, corners, ids)
    
    # ãƒãƒ¼ã‚«IDãŒå­˜åœ¨ã™ã‚‹ã‹
    if np.all(ids != None):
        # ç‰¹å®šã®ãƒãƒ¼ã‚«ãƒ¼ãŒèª­ã¿è¾¼ã¾ã‚ŒãŸã‚‰ç”»åƒã®ãƒã‚§ãƒ³ã‚¸
        if 10 in ids and agree:
            video.original_img = cv2.imread(random.choice(video.imgs))
            video.original_img = cv2.resize(video.original_img, dsize=(500, 500))
            video.img, video.comparison_img = video.imgCut(video.original_img, video.rows, video.cols)
            is_random_img = True
        else:
            is_random_img = False
            # cv2.imshow('img', original_img)
        
        # æ¤œå‡ºã•ã‚ŒãŸãƒãƒ¼ã‚«IDã®æ•°ã ã‘ç¹°ã‚Šè¿”ã™
        for i in range(len(ids)):
            # æ¤œå‡ºã•ã‚ŒãŸãƒãƒ¼ã‚«åº§æ¨™ã®ãƒ‡ãƒ¼ã‚¿
            pts_dst = np.array([
                (corners[i][0][0][0], corners[i][0][0][1]),
                (corners[i][0][1][0], corners[i][0][1][1]),
                (corners[i][0][2][0], corners[i][0][2][1]),
                (corners[i][0][3][0], corners[i][0][3][1]),
                    ])
            
            try:
                if ids[i] == 0 and len(video.img) >= 0:
                    frame, frame2 = video.overlapImg(video.img[0], pts_dst, frame, frame2)
                elif ids[i] == 1 and len(video.img) >= 1:
                    frame, frame2 = video.overlapImg(video.img[1], pts_dst, frame, frame2)
                elif ids[i] == 2 and len(video.img) >= 2:
                    frame, frame2 = video.overlapImg(video.img[2], pts_dst, frame, frame2)
                elif ids[i] == 3 and len(video.img) >= 3:
                    frame, frame2 = video.overlapImg(video.img[3], pts_dst, frame, frame2)
                elif ids[i] == 4 and len(video.img) >= 4:
                    frame, frame2 = video.overlapImg(video.img[4], pts_dst, frame, frame2)
                elif ids[i] == 5 and len(video.img) >= 5:
                    frame, frame2 = video.overlapImg(video.img[5], pts_dst, frame, frame2)
                elif ids[i] == 6 and len(video.img) >= 6:
                    frame, frame2 = video.overlapImg(video.img[6], pts_dst, frame, frame2)
                elif ids[i] == 7 and len(video.img) >= 7:
                    frame, frame2 = video.overlapImg(video.img[7], pts_dst, frame, frame2)
                elif ids[i] == 8 and len(video.img) >= 8:
                    frame, frame2 = video.overlapImg(video.img[8], pts_dst, frame, frame2)
                elif ids[i] == 9 and len(video.img) >= 9:
                    frame, frame2 = video.overlapImg(video.img[9], pts_dst, frame, frame2)
                elif ids[i] == 10 and len(video.img) >= 10:
                    frame, frame2 = video.overlapImg(video.img[10], pts_dst, frame, frame2)
                elif ids[i] == 11 and len(video.img) >= 11:
                    frame, frame2 = video.overlapImg(video.img[11], pts_dst, frame, frame2)
                elif ids[i] == 12 and len(video.img) >= 12:
                    frame, frame2 = video.overlapImg(video.img[12], pts_dst, frame, frame2)
                elif ids[i] == 13 and len(video.img) >= 13:
                    frame, frame2 = video.overlapImg(video.img[13], pts_dst, frame, frame2)
                elif ids[i] == 14 and len(video.img) >= 14:
                    frame, frame2 = video.overlapImg(video.img[14], pts_dst, frame, frame2)
                elif ids[i] == 15 and len(video.img) >= 15:
                    frame, frame2 = video.overlapImg(video.img[15], pts_dst, frame, frame2)
            except:
                pass
            
    frame3 = video.trimming(frame2)
    com = video.comparison(video.comparison_img, frame3, dsize)
    
    if  com > 0.9985:
        # ãƒ•ãƒ
        cv2.putText(frame, f'{com}%', (0, 50), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 0), 8, cv2.LINE_AA)
        # æ–‡å­—
        cv2.putText(frame, f'{com}%', (0, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, 10, 10), 3, cv2.LINE_AA)
    else:
        # ãƒ•ãƒ
        cv2.putText(frame, f'{com}%', (0, 50), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 0), 8, cv2.LINE_AA)
        # æ–‡å­—
        cv2.putText(frame, f'{com}%', (0, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, 255, 255), 3, cv2.LINE_AA)
        
    return av.VideoFrame.from_ndarray(frame, format="bgr24")

# https://github.com/whitphx/streamlit-webrtc#pull-values-from-the-callback
# lock = threading.Lock()
# result = {"percent": None, "ori_img": None}

ctx = webrtc_streamer(
    key="example", 
    video_frame_callback=video_frame_callback,
    # ã‚¯ãƒ©ã‚¹ã§ã™ã‚‹å ´åˆã¯video_processor_factoryã«ã™ã‚‹ã‹ã¤recvé–¢æ•°ã‚’frameå‡¦ç†ã«ä½¿ã†
    # video_processor_factory=VideoProcessor, 
    rtc_configuration={  # Add this config
        "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
    },
    # video_receiver_size = 10
    # media_stream_constraints={"video": True, "audio": False},
)
    
placeholder = st.sidebar.empty()
# æ­£ã—ã„ç”»åƒã®è¡¨ç¤º
if agree and ctx.state.playing:
    cou = 0
    while agree:
        # print(is_random_img)
        if is_random_img:
            cou += 1
            placeholder.image(video.cv2pil(video.original_img), caption='å…ƒç”»åƒ')
        else:
            placeholder.image(video.cv2pil(video.original_img), caption='å…ƒç”»åƒ')
        if not agree or cou > 500:
            print('of')
            agree = False
            break
else:
    placeholder.image(video.cv2pil(video.original_img), caption='å…ƒç”»åƒ')